{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8f4e7d62",
      "metadata": {
        "id": "8f4e7d62"
      },
      "source": [
        "# Doctor-Patient ASR Baseline Model\n",
        "\n",
        "This notebook implements a baseline ASR model for doctor-patient conversations using the Hugging Face dataset `Shamus/United-Syn-Med`.\n",
        "\n",
        "## Pipeline Overview:\n",
        "1. **Data Loading**: Stream subset from HF dataset\n",
        "2. **Preprocessing**: Audio resampling + feature extraction\n",
        "3. **Training**: Fine-tune Whisper Small/Tiny\n",
        "4. **Evaluation**: Compute WER metrics\n",
        "5. **Inference**: Test on validation samples\n",
        "\n",
        "Target: ~2000 samples (~500MB) for baseline prototype"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ece06a5",
      "metadata": {
        "id": "0ece06a5"
      },
      "source": [
        "## Setup and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4761114c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4761114c",
        "outputId": "9b554dd2-bab6-4fc0-89f2-5ff008545a3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cpu)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cpu)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.5)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (21.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.7.34)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.2.1)\n",
            "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from jiwer) (3.13.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard) (3.3.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from tensorboard) (11.3.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (6.31.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.34.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.8.3)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (2.0.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.61.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (5.2.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install datasets transformers torch torchaudio accelerate evaluate jiwer tensorboard\n",
        "!pip install --upgrade huggingface_hub\n",
        "# Install additional audio dependencies if needed\n",
        "!pip install soundfile librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0c6f6bce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c6f6bce",
        "outputId": "64d0f376-bd70-45bd-83e8-fcc18216bce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using model: openai/whisper-tiny\n",
            "Target samples: 2000\n",
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict, load_dataset\n",
        "from transformers import (\n",
        "    WhisperProcessor,\n",
        "    WhisperForConditionalGeneration,\n",
        "    WhisperTokenizer,\n",
        "    WhisperFeatureExtractor,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n",
        "import evaluate\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration\n",
        "CONFIG = {\n",
        "    'dataset_name': 'Shamus/United-Syn-Med',\n",
        "    'model_name': 'openai/whisper-tiny',  # Change to 'openai/whisper-tiny' for faster testing\n",
        "    'num_samples': 2000,\n",
        "    'target_sample_rate': 16000,\n",
        "    'train_split_ratio': 0.8,\n",
        "    'output_dir': './whisper-medical-asr',\n",
        "    'max_audio_length': 30.0,  # seconds\n",
        "    'batch_size': 8,\n",
        "    'num_epochs': 3,\n",
        "    'learning_rate': 1e-5,\n",
        "    'warmup_steps': 500,\n",
        "    'eval_steps': 500,\n",
        "    'save_steps': 1000,\n",
        "    'gradient_accumulation_steps': 2\n",
        "}\n",
        "\n",
        "print(f\"Using model: {CONFIG['model_name']}\")\n",
        "print(f\"Target samples: {CONFIG['num_samples']}\")\n",
        "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21dded15",
      "metadata": {
        "id": "21dded15"
      },
      "source": [
        "## Module 1: Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "10fc4022",
      "metadata": {
        "id": "10fc4022"
      },
      "outputs": [],
      "source": [
        "class DataLoader:\n",
        "    \"\"\"Handles loading and streaming of the medical conversation dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, dataset_name: str, num_samples: int, train_split_ratio: float = 0.8):\n",
        "        self.dataset_name = dataset_name\n",
        "        self.num_samples = num_samples\n",
        "        self.train_split_ratio = train_split_ratio\n",
        "        self.raw_data = None\n",
        "\n",
        "    def load_dataset_subset(self) -> List[Dict]:\n",
        "        \"\"\"Load a subset of the dataset using direct parquet access to avoid audio decoding issues.\"\"\"\n",
        "        print(f\"Loading {self.num_samples} samples from {self.dataset_name}...\")\n",
        "\n",
        "        try:\n",
        "            # Method 1: Direct parquet loading to avoid audio decoding\n",
        "            print(\"Attempting direct parquet loading...\")\n",
        "            samples = self._load_from_parquet()\n",
        "            if samples:\n",
        "                self.raw_data = samples\n",
        "                return samples\n",
        "        except Exception as e:\n",
        "            print(f\"Parquet loading failed: {e}\")\n",
        "\n",
        "        try:\n",
        "            # Method 2: Use datasets library but process samples carefully\n",
        "            print(\"Attempting careful streaming with manual audio handling...\")\n",
        "            samples = self._load_with_manual_processing()\n",
        "            if samples:\n",
        "                self.raw_data = samples\n",
        "                return samples\n",
        "        except Exception as e:\n",
        "            print(f\"Manual processing failed: {e}\")\n",
        "\n",
        "        raise Exception(\"All loading methods failed\")\n",
        "\n",
        "    def _load_from_parquet(self) -> List[Dict]:\n",
        "        \"\"\"Load dataset directly from parquet files.\"\"\"\n",
        "        import pandas as pd\n",
        "        from huggingface_hub import list_repo_files\n",
        "\n",
        "        # Get parquet files\n",
        "        files = list_repo_files(self.dataset_name, repo_type=\"dataset\")\n",
        "        parquet_files = [f for f in files if f.endswith('.parquet') and 'train' in f]\n",
        "\n",
        "        if not parquet_files:\n",
        "            raise Exception(\"No parquet files found\")\n",
        "\n",
        "        print(f\"Found {len(parquet_files)} parquet files\")\n",
        "\n",
        "        samples = []\n",
        "        samples_per_file = self.num_samples // len(parquet_files) + 1\n",
        "\n",
        "        for file_idx, file_path in enumerate(parquet_files):\n",
        "            if len(samples) >= self.num_samples:\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                print(f\"Loading from {file_path}...\")\n",
        "                file_url = f\"https://huggingface.co/datasets/{self.dataset_name}/resolve/main/{file_path}\"\n",
        "                df = pd.read_parquet(file_url, engine='pyarrow')\n",
        "\n",
        "                # Take only the samples we need from this file\n",
        "                remaining_samples = self.num_samples - len(samples)\n",
        "                df_subset = df.head(min(samples_per_file, remaining_samples))\n",
        "\n",
        "                for _, row in df_subset.iterrows():\n",
        "                    if len(samples) >= self.num_samples:\n",
        "                        break\n",
        "\n",
        "                    # Convert row to dict and handle audio separately\n",
        "                    sample = {}\n",
        "                    for col, value in row.items():\n",
        "                        if col == 'audio':\n",
        "                            # Keep audio as raw data structure\n",
        "                            if isinstance(value, dict):\n",
        "                                sample[col] = value\n",
        "                            else:\n",
        "                                # If it's a different format, create a dict structure\n",
        "                                sample[col] = {'bytes': value, 'path': None, 'sampling_rate': 16000}\n",
        "                        elif col == 'transcription':\n",
        "                            # Map transcription to text field\n",
        "                            sample['text'] = str(value) if value is not None else \"\"\n",
        "                        else:\n",
        "                            sample[col] = value\n",
        "\n",
        "                    # Ensure we have a text field\n",
        "                    if 'text' not in sample:\n",
        "                        sample['text'] = \"\"\n",
        "\n",
        "                    samples.append(sample)\n",
        "\n",
        "                print(f\"Loaded {len(samples)} samples so far...\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {file_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "        return samples\n",
        "\n",
        "    def _load_with_manual_processing(self) -> List[Dict]:\n",
        "        \"\"\"Fallback method using datasets library with careful processing.\"\"\"\n",
        "        # Try loading without any schema constraints\n",
        "        dataset_stream = load_dataset(\n",
        "            self.dataset_name,\n",
        "            split='train',\n",
        "            streaming=True\n",
        "        )\n",
        "\n",
        "        samples = []\n",
        "        error_count = 0\n",
        "        max_errors = 10  # Allow some errors before giving up\n",
        "\n",
        "        iterator = iter(dataset_stream)\n",
        "\n",
        "        while len(samples) < self.num_samples and error_count < max_errors:\n",
        "            try:\n",
        "                sample = next(iterator)\n",
        "\n",
        "                # Process sample carefully\n",
        "                processed_sample = {}\n",
        "\n",
        "                for key, value in sample.items():\n",
        "                    if key == 'audio':\n",
        "                        # Try to keep audio without triggering decoding\n",
        "                        if hasattr(value, 'keys') and callable(getattr(value, 'keys')):\n",
        "                            # It's dict-like, extract raw data\n",
        "                            processed_sample[key] = {\n",
        "                                'bytes': getattr(value, 'bytes', None),\n",
        "                                'path': getattr(value, 'path', None),\n",
        "                                'sampling_rate': getattr(value, 'sampling_rate', 16000)\n",
        "                            }\n",
        "                        else:\n",
        "                            # Store as-is and hope for the best\n",
        "                            processed_sample[key] = value\n",
        "                    elif key == 'transcription':\n",
        "                        processed_sample['text'] = str(value) if value is not None else \"\"\n",
        "                    else:\n",
        "                        processed_sample[key] = value\n",
        "\n",
        "                # Ensure text field exists\n",
        "                if 'text' not in processed_sample:\n",
        "                    processed_sample['text'] = \"\"\n",
        "\n",
        "                samples.append(processed_sample)\n",
        "\n",
        "                if (len(samples) + 1) % 100 == 0:\n",
        "                    print(f\"Loaded {len(samples)} samples...\")\n",
        "\n",
        "            except StopIteration:\n",
        "                print(\"Reached end of dataset\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                error_count += 1\n",
        "                print(f\"Error processing sample {len(samples) + error_count}: {e}\")\n",
        "                if error_count >= max_errors:\n",
        "                    print(f\"Too many errors ({error_count}), stopping...\")\n",
        "                    break\n",
        "\n",
        "        return samples\n",
        "\n",
        "    def create_train_val_split(self, samples: List[Dict]) -> Tuple[Dataset, Dataset]:\n",
        "        \"\"\"Split the data into train and validation sets.\"\"\"\n",
        "        split_idx = int(len(samples) * self.train_split_ratio)\n",
        "\n",
        "        train_samples = samples[:split_idx]\n",
        "        val_samples = samples[split_idx:]\n",
        "\n",
        "        # Convert to HF datasets\n",
        "        train_dataset = Dataset.from_list(train_samples)\n",
        "        val_dataset = Dataset.from_list(val_samples)\n",
        "\n",
        "        print(f\"Train samples: {len(train_dataset)}\")\n",
        "        print(f\"Validation samples: {len(val_dataset)}\")\n",
        "\n",
        "        return train_dataset, val_dataset\n",
        "\n",
        "    def inspect_sample(self, idx: int = 0) -> None:\n",
        "        \"\"\"Inspect a sample to understand the data structure.\"\"\"\n",
        "        if self.raw_data is None:\n",
        "            print(\"No data loaded. Run load_dataset_subset() first.\")\n",
        "            return\n",
        "\n",
        "        sample = self.raw_data[idx]\n",
        "        print(f\"Sample {idx} structure:\")\n",
        "        for key, value in sample.items():\n",
        "            if key == 'audio':\n",
        "                if isinstance(value, dict):\n",
        "                    print(f\"  {key}: dict with keys {list(value.keys())}\")\n",
        "                    for sub_key, sub_value in value.items():\n",
        "                        if sub_key == 'bytes' and sub_value is not None:\n",
        "                            print(f\"    {sub_key}: {len(sub_value)} bytes\")\n",
        "                        else:\n",
        "                            print(f\"    {sub_key}: {sub_value}\")\n",
        "                else:\n",
        "                    print(f\"  {key}: {type(value)}\")\n",
        "            else:\n",
        "                print(f\"  {key}: {str(value)[:100]}...\" if len(str(value)) > 100 else f\"  {key}: {value}\")\n",
        "\n",
        "# Initialize data loader\n",
        "data_loader = DataLoader(\n",
        "    dataset_name=CONFIG['dataset_name'],\n",
        "    num_samples=CONFIG['num_samples'],\n",
        "    train_split_ratio=CONFIG['train_split_ratio']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test cell to examine the original dataset structure without triggering audio decoding\n",
        "def check_dataset_structure_safe():\n",
        "    \"\"\"Check the actual structure of the dataset without triggering audio decoding.\"\"\"\n",
        "    print(\"Examining dataset structure safely...\")\n",
        "\n",
        "    try:\n",
        "        # Load dataset info without streaming to avoid audio decoding\n",
        "        from datasets import get_dataset_config_names, get_dataset_split_names\n",
        "        from datasets.utils.info_utils import get_dataset_infos\n",
        "\n",
        "        print(\"Dataset configs:\", get_dataset_config_names(CONFIG['dataset_name']))\n",
        "        print(\"Dataset splits:\", get_dataset_split_names(CONFIG['dataset_name']))\n",
        "\n",
        "        # Try to get dataset info\n",
        "        dataset_infos = get_dataset_infos(CONFIG['dataset_name'])\n",
        "        print(\"Dataset info keys:\", list(dataset_infos.keys()))\n",
        "\n",
        "        # If we have default config, print its features\n",
        "        if 'default' in dataset_infos:\n",
        "            features = dataset_infos['default'].features\n",
        "            print(\"Dataset features:\")\n",
        "            for name, feature in features.items():\n",
        "                print(f\"  {name}: {feature}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting dataset info: {e}\")\n",
        "\n",
        "        # Alternative: try loading parquet files directly\n",
        "        try:\n",
        "            print(\"Trying direct parquet approach...\")\n",
        "            import pandas as pd\n",
        "            from huggingface_hub import list_repo_files\n",
        "\n",
        "            # List files in the repository\n",
        "            files = list_repo_files(CONFIG['dataset_name'], repo_type=\"dataset\")\n",
        "            parquet_files = [f for f in files if f.endswith('.parquet') and 'train' in f]\n",
        "            print(f\"Found {len(parquet_files)} training parquet files\")\n",
        "\n",
        "            if parquet_files:\n",
        "                # Load just the first few rows of the first parquet file to check structure\n",
        "                first_file = parquet_files[0]\n",
        "                print(f\"Examining first file: {first_file}\")\n",
        "\n",
        "                # Load parquet file directly\n",
        "                file_url = f\"https://huggingface.co/datasets/{CONFIG['dataset_name']}/resolve/main/{first_file}\"\n",
        "                df_sample = pd.read_parquet(file_url, engine='pyarrow').head(3)\n",
        "\n",
        "                print(\"Parquet file structure:\")\n",
        "                print(f\"Columns: {list(df_sample.columns)}\")\n",
        "                print(f\"Shape: {df_sample.shape}\")\n",
        "\n",
        "                for col in df_sample.columns:\n",
        "                    print(f\"  {col}: {df_sample[col].dtype}\")\n",
        "                    if col != 'audio':  # Skip audio column to avoid issues\n",
        "                        print(f\"    Sample value: {str(df_sample[col].iloc[0])[:100]}...\")\n",
        "\n",
        "                return df_sample\n",
        "\n",
        "        except Exception as e2:\n",
        "            print(f\"Parquet approach also failed: {e2}\")\n",
        "            return None\n",
        "\n",
        "# Run the safe structure check\n",
        "print(\"Checking dataset structure safely...\")\n",
        "sample_structure = check_dataset_structure_safe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSgb7prEDy_O",
        "outputId": "63244899-4d1c-4d9c-8ae5-103a14b67733"
      },
      "id": "OSgb7prEDy_O",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking dataset structure safely...\n",
            "Examining dataset structure safely...\n",
            "Error getting dataset info: cannot import name 'get_dataset_infos' from 'datasets.utils.info_utils' (/usr/local/lib/python3.11/dist-packages/datasets/utils/info_utils.py)\n",
            "Trying direct parquet approach...\n",
            "Found 33 training parquet files\n",
            "Examining first file: data/train-00000-of-00033.parquet\n",
            "Parquet file structure:\n",
            "Columns: ['audio', 'transcription']\n",
            "Shape: (3, 2)\n",
            "  audio: object\n",
            "  transcription: object\n",
            "    Sample value: Durysta is a medication used to reduce eye pressure in patients with open-angle glaucoma or ocular h...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "caa97aeb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caa97aeb",
        "outputId": "6d4aedd0-f5bc-4ca8-8a75-f4955a131c5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 2000 samples from Shamus/United-Syn-Med...\n",
            "Attempting direct parquet loading...\n",
            "Found 33 parquet files\n",
            "Loading from data/train-00000-of-00033.parquet...\n",
            "Loaded 61 samples so far...\n",
            "Loading from data/train-00001-of-00033.parquet...\n",
            "Loaded 122 samples so far...\n",
            "Loading from data/train-00002-of-00033.parquet...\n",
            "Loaded 183 samples so far...\n",
            "Loading from data/train-00003-of-00033.parquet...\n",
            "Loaded 244 samples so far...\n",
            "Loading from data/train-00004-of-00033.parquet...\n",
            "Loaded 305 samples so far...\n",
            "Loading from data/train-00005-of-00033.parquet...\n",
            "Loaded 366 samples so far...\n",
            "Loading from data/train-00006-of-00033.parquet...\n",
            "Loaded 427 samples so far...\n",
            "Loading from data/train-00007-of-00033.parquet...\n",
            "Loaded 488 samples so far...\n",
            "Loading from data/train-00008-of-00033.parquet...\n",
            "Loaded 549 samples so far...\n",
            "Loading from data/train-00009-of-00033.parquet...\n",
            "Loaded 610 samples so far...\n",
            "Loading from data/train-00010-of-00033.parquet...\n",
            "Loaded 671 samples so far...\n",
            "Loading from data/train-00011-of-00033.parquet...\n",
            "Loaded 732 samples so far...\n",
            "Loading from data/train-00012-of-00033.parquet...\n",
            "Loaded 793 samples so far...\n",
            "Loading from data/train-00013-of-00033.parquet...\n",
            "Loaded 854 samples so far...\n",
            "Loading from data/train-00014-of-00033.parquet...\n",
            "Loaded 915 samples so far...\n",
            "Loading from data/train-00015-of-00033.parquet...\n",
            "Loaded 976 samples so far...\n",
            "Loading from data/train-00016-of-00033.parquet...\n",
            "Loaded 1037 samples so far...\n",
            "Loading from data/train-00017-of-00033.parquet...\n",
            "Loaded 1098 samples so far...\n",
            "Loading from data/train-00018-of-00033.parquet...\n",
            "Loaded 1159 samples so far...\n",
            "Loading from data/train-00019-of-00033.parquet...\n",
            "Loaded 1220 samples so far...\n",
            "Loading from data/train-00020-of-00033.parquet...\n",
            "Loaded 1281 samples so far...\n",
            "Loading from data/train-00021-of-00033.parquet...\n",
            "Loaded 1342 samples so far...\n",
            "Loading from data/train-00022-of-00033.parquet...\n",
            "Loaded 1403 samples so far...\n",
            "Loading from data/train-00023-of-00033.parquet...\n",
            "Loaded 1464 samples so far...\n",
            "Loading from data/train-00024-of-00033.parquet...\n",
            "Loaded 1525 samples so far...\n",
            "Loading from data/train-00025-of-00033.parquet...\n",
            "Loaded 1586 samples so far...\n",
            "Loading from data/train-00026-of-00033.parquet...\n",
            "Loaded 1647 samples so far...\n",
            "Loading from data/train-00027-of-00033.parquet...\n",
            "Loaded 1708 samples so far...\n",
            "Loading from data/train-00028-of-00033.parquet...\n",
            "Loaded 1769 samples so far...\n",
            "Loading from data/train-00029-of-00033.parquet...\n",
            "Loaded 1830 samples so far...\n",
            "Loading from data/train-00030-of-00033.parquet...\n",
            "Loaded 1891 samples so far...\n",
            "Loading from data/train-00031-of-00033.parquet...\n",
            "Loaded 1952 samples so far...\n",
            "Loading from data/train-00032-of-00033.parquet...\n",
            "Loaded 2000 samples so far...\n",
            "Sample 0 structure:\n",
            "  audio: dict with keys ['bytes', 'path']\n",
            "    bytes: 65613 bytes\n",
            "    path: drug-female-defa7fcb-89d7-4b25-8834-90888b201d25.mp3\n",
            "  text: Durysta is a medication used to reduce eye pressure in patients with open-angle glaucoma or ocular h...\n",
            "\n",
            "==================================================\n",
            "Testing audio decoding...\n",
            "Audio stored as bytes - decoding...\n",
            "Successfully decoded audio: shape=torch.Size([1, 178150]), sample_rate=24000\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset subset\n",
        "samples = data_loader.load_dataset_subset()\n",
        "\n",
        "# Inspect a sample to understand the structure\n",
        "data_loader.inspect_sample(0)\n",
        "\n",
        "# Test audio decoding on the first sample\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Testing audio decoding...\")\n",
        "try:\n",
        "    first_sample = samples[0]\n",
        "    audio_info = first_sample['audio']\n",
        "\n",
        "    # Try to decode the audio manually\n",
        "    import io\n",
        "    if 'bytes' in audio_info and audio_info['bytes'] is not None:\n",
        "        print(\"Audio stored as bytes - decoding...\")\n",
        "        audio_bytes = audio_info['bytes']\n",
        "        audio_file = io.BytesIO(audio_bytes)\n",
        "        waveform, sample_rate = torchaudio.load(audio_file)\n",
        "        print(f\"Successfully decoded audio: shape={waveform.shape}, sample_rate={sample_rate}\")\n",
        "    elif 'path' in audio_info:\n",
        "        print(f\"Audio path: {audio_info['path']}\")\n",
        "        waveform, sample_rate = torchaudio.load(audio_info['path'])\n",
        "        print(f\"Successfully loaded audio: shape={waveform.shape}, sample_rate={sample_rate}\")\n",
        "    else:\n",
        "        print(f\"Unexpected audio format: {audio_info}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error decoding audio: {e}\")\n",
        "    print(\"This might indicate an issue with the audio format.\")\n",
        "\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f518969",
      "metadata": {
        "id": "5f518969"
      },
      "source": [
        "## Module 2: Audio Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "3af9c017",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3af9c017",
        "outputId": "8b583491-ff65-4842-fdd4-ee5add57dfa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Whisper processor for openai/whisper-tiny...\n",
            "Processor loaded. Target sample rate: 16000Hz\n"
          ]
        }
      ],
      "source": [
        "class AudioPreprocessor:\n",
        "    \"\"\"Handles audio preprocessing for Whisper model.\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str, target_sample_rate: int = 16000, max_audio_length: float = 30.0):\n",
        "        self.model_name = model_name\n",
        "        self.target_sample_rate = target_sample_rate\n",
        "        self.max_audio_length = max_audio_length\n",
        "\n",
        "        # Initialize Whisper components\n",
        "        print(f\"Loading Whisper processor for {model_name}...\")\n",
        "        self.processor = WhisperProcessor.from_pretrained(model_name)\n",
        "        self.feature_extractor = self.processor.feature_extractor\n",
        "        self.tokenizer = self.processor.tokenizer\n",
        "\n",
        "        print(f\"Processor loaded. Target sample rate: {self.target_sample_rate}Hz\")\n",
        "\n",
        "    def decode_audio_bytes(self, audio_info: Dict) -> Tuple[np.ndarray, int]:\n",
        "        \"\"\"Decode audio from bytes using torchaudio.\"\"\"\n",
        "        import io\n",
        "\n",
        "        if 'bytes' in audio_info and audio_info['bytes'] is not None:\n",
        "            # Load audio from bytes\n",
        "            audio_bytes = audio_info['bytes']\n",
        "            audio_file = io.BytesIO(audio_bytes)\n",
        "\n",
        "            # Use torchaudio to load the audio\n",
        "            waveform, sample_rate = torchaudio.load(audio_file)\n",
        "\n",
        "            # Convert to numpy and handle multi-channel audio\n",
        "            audio_array = waveform.numpy()\n",
        "            if len(audio_array.shape) > 1:\n",
        "                # Convert to mono by averaging channels\n",
        "                audio_array = np.mean(audio_array, axis=0)\n",
        "\n",
        "            return audio_array, sample_rate\n",
        "\n",
        "        elif 'path' in audio_info and audio_info['path'] is not None:\n",
        "            # Load audio from file path\n",
        "            waveform, sample_rate = torchaudio.load(audio_info['path'])\n",
        "\n",
        "            # Convert to numpy and handle multi-channel audio\n",
        "            audio_array = waveform.numpy()\n",
        "            if len(audio_array.shape) > 1:\n",
        "                # Convert to mono by averaging channels\n",
        "                audio_array = np.mean(audio_array, axis=0)\n",
        "\n",
        "            return audio_array, sample_rate\n",
        "\n",
        "        elif 'array' in audio_info:\n",
        "            # Already decoded audio\n",
        "            return np.array(audio_info['array']), audio_info.get('sampling_rate', 16000)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported audio format: {audio_info.keys()}\")\n",
        "\n",
        "    def resample_audio(self, audio_array: np.ndarray, original_sr: int) -> np.ndarray:\n",
        "        \"\"\"Resample audio to target sample rate.\"\"\"\n",
        "        if original_sr == self.target_sample_rate:\n",
        "            return audio_array\n",
        "\n",
        "        # Convert to tensor for resampling\n",
        "        audio_tensor = torch.from_numpy(audio_array).float()\n",
        "        if len(audio_tensor.shape) == 1:\n",
        "            audio_tensor = audio_tensor.unsqueeze(0)  # Add channel dimension\n",
        "\n",
        "        # Resample\n",
        "        resampler = torchaudio.transforms.Resample(\n",
        "            orig_freq=original_sr,\n",
        "            new_freq=self.target_sample_rate\n",
        "        )\n",
        "        resampled = resampler(audio_tensor)\n",
        "\n",
        "        return resampled.squeeze().numpy()\n",
        "\n",
        "    def trim_or_pad_audio(self, audio_array: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Trim or pad audio to max length.\"\"\"\n",
        "        max_samples = int(self.max_audio_length * self.target_sample_rate)\n",
        "\n",
        "        if len(audio_array) > max_samples:\n",
        "            # Trim to max length\n",
        "            return audio_array[:max_samples]\n",
        "        elif len(audio_array) < max_samples:\n",
        "            # Pad with zeros\n",
        "            padding = max_samples - len(audio_array)\n",
        "            return np.pad(audio_array, (0, padding), mode='constant')\n",
        "        else:\n",
        "            return audio_array\n",
        "\n",
        "    def preprocess_batch(self, batch: Dict) -> Dict:\n",
        "        \"\"\"Preprocess a batch of audio samples.\"\"\"\n",
        "        # Extract audio data\n",
        "        audio_data = []\n",
        "        texts = []\n",
        "\n",
        "        for i in range(len(batch['audio'])):\n",
        "            try:\n",
        "                # Handle audio - decode from bytes/path\n",
        "                audio_info = batch['audio'][i]\n",
        "                audio_array, sampling_rate = self.decode_audio_bytes(audio_info)\n",
        "\n",
        "                # Preprocess audio\n",
        "                audio_array = self.resample_audio(audio_array, sampling_rate)\n",
        "                audio_array = self.trim_or_pad_audio(audio_array)\n",
        "                audio_data.append(audio_array)\n",
        "\n",
        "                # Handle text (check multiple possible field names)\n",
        "                text_field = \"\"\n",
        "                for field in ['text', 'transcription', 'sentence', 'transcript']:\n",
        "                    if field in batch and i < len(batch[field]):\n",
        "                        text_field = batch[field][i]\n",
        "                        break\n",
        "\n",
        "                if text_field is None:\n",
        "                    text_field = \"\"  # Empty fallback\n",
        "                texts.append(str(text_field))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing sample {i}: {e}\")\n",
        "                # Skip this sample or use empty data\n",
        "                audio_data.append(np.zeros(int(self.max_audio_length * self.target_sample_rate)))\n",
        "                texts.append(\"\")\n",
        "\n",
        "        # Process with Whisper feature extractor\n",
        "        features = self.feature_extractor(\n",
        "            audio_data,\n",
        "            sampling_rate=self.target_sample_rate,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True\n",
        "        )\n",
        "\n",
        "        # Tokenize texts - IMPORTANT: Use the correct format for Whisper\n",
        "        with self.tokenizer.as_target_tokenizer():\n",
        "            labels = self.tokenizer(\n",
        "                texts,\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\"\n",
        "            ).input_ids\n",
        "\n",
        "        # Replace padding token id with -100 so it's ignored in loss computation\n",
        "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        return {\n",
        "            \"input_features\": features[\"input_features\"],\n",
        "            \"labels\": labels\n",
        "        }\n",
        "\n",
        "# Initialize preprocessor\n",
        "preprocessor = AudioPreprocessor(\n",
        "    model_name=CONFIG['model_name'],\n",
        "    target_sample_rate=CONFIG['target_sample_rate'],\n",
        "    max_audio_length=CONFIG['max_audio_length']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test preprocessed data structure\n",
        "def test_preprocessed_data():\n",
        "    \"\"\"Test that the preprocessed data has the correct structure for training.\"\"\"\n",
        "    print(\"Testing preprocessed data structure...\")\n",
        "\n",
        "    # Get a sample from the training dataset\n",
        "    sample = train_dataset[0]\n",
        "    print(f\"Sample keys: {list(sample.keys())}\")\n",
        "\n",
        "    for key, value in sample.items():\n",
        "        if isinstance(value, torch.Tensor):\n",
        "            print(f\"{key}: tensor with shape {value.shape}\")\n",
        "        else:\n",
        "            print(f\"{key}: {type(value)}\")\n",
        "\n",
        "    # Test data collator\n",
        "    data_collator = whisper_trainer.create_data_collator()\n",
        "\n",
        "    # Try to collate a small batch\n",
        "    batch_samples = [train_dataset[i] for i in range(min(2, len(train_dataset)))]\n",
        "    try:\n",
        "        collated_batch = data_collator(batch_samples)\n",
        "        print(\"\\nCollated batch structure:\")\n",
        "        for key, value in collated_batch.items():\n",
        "            if isinstance(value, torch.Tensor):\n",
        "                print(f\"{key}: tensor with shape {value.shape}\")\n",
        "            else:\n",
        "                print(f\"{key}: {type(value)}\")\n",
        "        print(\" Data collation successful!\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\" Data collation failed: {e}\")\n",
        "        return False\n",
        "\n",
        "# Run the test\n",
        "test_success = test_preprocessed_data()"
      ],
      "metadata": {
        "id": "a5GQv7CKJHsJ"
      },
      "id": "a5GQv7CKJHsJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "dc0790e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202,
          "referenced_widgets": [
            "7503814d808e4eb690bd18878830c037",
            "5b12f3652e0943f382d4a2647f52e24d",
            "56184a1862b24d3e938478d43ffd40b2",
            "c2ecdc4d35f148fb88b3b1811ff6e48b",
            "27c5333a825e4bae9bfed11e68d63c91",
            "827727c5571c4e549b19ba833383cc04",
            "7985d3a353ee439b86b487ed517a6045",
            "eb7b53a0ad044e41b492ed7a1141b5cd",
            "e1b5069892be4d19b4137d1e63f8f39b",
            "cc59d945a8fb40fa90b76935e5e25abe",
            "e283cc8f91ac4715b9b4559bc7e7fc97",
            "436f694571ed47a9b5245958dbdd5c57",
            "bec3765290944905b31bd83ccc7df5dc",
            "3f17f79f05574da18beb005d42a24949",
            "160f17b30ba54275b7a63786006d9685",
            "ecaf6210046e492e80b7cf0d1b096643",
            "33733c1510024b019402d79e63128885",
            "d5e1612fec2f423fa752900b5cb7923d",
            "711f01944c904cf4a774cd9c446a8ea2",
            "a4d7ae0ed68c4e7286f6b07e241fbfa5",
            "c4c90494c98f4ac2bbf0ca2b787d624e",
            "3a3a3e7e601f44c49e120d1d77948891"
          ]
        },
        "id": "dc0790e4",
        "outputId": "e2566abb-d0ca-457e-d0bc-0b22cfd6be11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 1600\n",
            "Validation samples: 400\n",
            "Preprocessing training data...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7503814d808e4eb690bd18878830c037"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing validation data...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "436f694571ed47a9b5245958dbdd5c57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing complete!\n",
            "Train dataset: 1600 samples\n",
            "Val dataset: 400 samples\n"
          ]
        }
      ],
      "source": [
        "# Create train/val splits\n",
        "train_dataset, val_dataset = data_loader.create_train_val_split(samples)\n",
        "\n",
        "# Apply preprocessing to datasets\n",
        "print(\"Preprocessing training data...\")\n",
        "train_dataset = train_dataset.map(\n",
        "    preprocessor.preprocess_batch,\n",
        "    batched=True,\n",
        "    batch_size=8,\n",
        "    remove_columns=train_dataset.column_names\n",
        ")\n",
        "\n",
        "print(\"Preprocessing validation data...\")\n",
        "val_dataset = val_dataset.map(\n",
        "    preprocessor.preprocess_batch,\n",
        "    batched=True,\n",
        "    batch_size=8,\n",
        "    remove_columns=val_dataset.column_names\n",
        ")\n",
        "\n",
        "print(\"Preprocessing complete!\")\n",
        "print(f\"Train dataset: {len(train_dataset)} samples\")\n",
        "print(f\"Val dataset: {len(val_dataset)} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22094e74",
      "metadata": {
        "id": "22094e74"
      },
      "source": [
        "## Module 3: Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c17d828d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148,
          "referenced_widgets": [
            "e943bb857ae7498c8598f2c53d5e309f",
            "1cf9cdde54104a36812ef53fd76d30b2",
            "3f67cc6429c242f1a3d4d3175ad12376",
            "ff7986d246de4b1584a3b65d1831a71f",
            "ba8d5a10ec414c6e880e587f2245b4bf",
            "30edfbd789fd47c480c7790bf3a5a1f9",
            "2f8e359964a94e0b98185c8accf828a4",
            "148ed113e6bc42cb9f8db99a7ec24501",
            "0f6805f03105477db2fe1936667dceed",
            "a01c9677805f4bb0be8e40e8ca981db6",
            "bee8104aa7034fa694c4f7d7d22ed17d",
            "13ffc6bc1157413085ac279bc1a3b1c2",
            "fb5d27bed62343ab9b7288dbdff3a4d0",
            "26722dabb6b547c09aba4f36a9f02e92",
            "d20490cc7b6b4b78997a4c2bafcbe56f",
            "fb55a84387814c1fa4fc31d929cb8e37",
            "14390d6438a24acda32f30551e641082",
            "0e12614b29f4439581a5abd62e3df57e",
            "5de06bb4bd5c42919fd22b2128fab43f",
            "7d4e4bd257e94331ab4220e95f155a7a",
            "faddce1711bf42f197a69166a4bb8950",
            "9a93ba39234c46f2a2a0479d023af55c",
            "70118b8f3de84318939bd1175fb1c30d",
            "a2718c23fbf44259826b11ede3c01985",
            "b260b1f8b7954b039dbb422f4a992452",
            "e4adf9f679cb4eed89f3303fa31ae9dc",
            "723635fe203d4fcabc1a6f26beb9ad17",
            "d7ccace2bc0249ef87c513f97150aef9",
            "b0a86439822d43c6a22c8fb925929c92",
            "86166738aa664bfc98e17ce7c5a0bed0",
            "a38371bde29244a1a54980f7db83d4fc",
            "ee91dbe1383c4798a8098d7dc6713be9",
            "0c879a59d46742fdb8ecf01b982c74eb"
          ]
        },
        "id": "c17d828d",
        "outputId": "09f1745b-35de-4488-b260-087142237998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Whisper model: openai/whisper-tiny...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e943bb857ae7498c8598f2c53d5e309f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/151M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13ffc6bc1157413085ac279bc1a3b1c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70118b8f3de84318939bd1175fb1c30d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded. Parameters: 37,760,640\n"
          ]
        }
      ],
      "source": [
        "class WhisperTrainer:\n",
        "    \"\"\"Handles Whisper model training and fine-tuning.\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str, output_dir: str):\n",
        "        self.model_name = model_name\n",
        "        self.output_dir = output_dir\n",
        "\n",
        "        # Load model and processor\n",
        "        print(f\"Loading Whisper model: {model_name}...\")\n",
        "        self.model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
        "        self.processor = WhisperProcessor.from_pretrained(model_name)\n",
        "\n",
        "        # Force decoder to use correct language tokens\n",
        "        self.model.config.forced_decoder_ids = None\n",
        "        self.model.config.suppress_tokens = []\n",
        "\n",
        "        print(f\"Model loaded. Parameters: {self.model.num_parameters():,}\")\n",
        "\n",
        "    def create_data_collator(self):\n",
        "        \"\"\"Create data collator for training.\"\"\"\n",
        "        # Use a simple data collator that doesn't interfere with our preprocessing\n",
        "        from transformers import DefaultDataCollator\n",
        "        return DefaultDataCollator()\n",
        "\n",
        "    def setup_training_args(self, config: Dict) -> TrainingArguments:\n",
        "        \"\"\"Setup training arguments.\"\"\"\n",
        "        return TrainingArguments(\n",
        "            output_dir=self.output_dir,\n",
        "            per_device_train_batch_size=config['batch_size'],\n",
        "            per_device_eval_batch_size=config['batch_size'],\n",
        "            gradient_accumulation_steps=config['gradient_accumulation_steps'],\n",
        "            learning_rate=config['learning_rate'],\n",
        "            warmup_steps=config['warmup_steps'],\n",
        "            num_train_epochs=config['num_epochs'],\n",
        "            eval_strategy=\"steps\",\n",
        "            eval_steps=config['eval_steps'],\n",
        "            save_steps=config['save_steps'],\n",
        "            logging_steps=50,\n",
        "            save_total_limit=2,\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"eval_loss\",\n",
        "            greater_is_better=False,\n",
        "            fp16=True if torch.cuda.is_available() else False,\n",
        "            dataloader_pin_memory=False,\n",
        "            report_to=[\"tensorboard\"],\n",
        "            push_to_hub=False,\n",
        "            remove_unused_columns=False,\n",
        "            dataloader_num_workers=0,  # Avoid multiprocessing issues\n",
        "        )\n",
        "\n",
        "    def create_trainer(self, train_dataset: Dataset, val_dataset: Dataset, config: Dict) -> Trainer:\n",
        "        \"\"\"Create and configure the trainer.\"\"\"\n",
        "        training_args = self.setup_training_args(config)\n",
        "        data_collator = self.create_data_collator()\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            data_collator=data_collator,\n",
        "            tokenizer=self.processor.tokenizer\n",
        "        )\n",
        "\n",
        "        return trainer\n",
        "\n",
        "    def train(self, train_dataset: Dataset, val_dataset: Dataset, config: Dict):\n",
        "        \"\"\"Train the model.\"\"\"\n",
        "        print(\"Setting up trainer...\")\n",
        "        trainer = self.create_trainer(train_dataset, val_dataset, config)\n",
        "\n",
        "        print(\"Starting training...\")\n",
        "        trainer.train()\n",
        "\n",
        "        print(\"Saving final model...\")\n",
        "        trainer.save_model()\n",
        "        self.processor.save_pretrained(self.output_dir)\n",
        "\n",
        "        return trainer\n",
        "\n",
        "# Initialize trainer\n",
        "whisper_trainer = WhisperTrainer(\n",
        "    model_name=CONFIG['model_name'],\n",
        "    output_dir=CONFIG['output_dir']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ceeec91",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ceeec91",
        "outputId": "40aa4ec2-b1d7-4be0-8b17-12603a488245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting model training...\n",
            "Setting up trainer...\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-6 (_loader_worker):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch_xla/distributed/parallel_loader.py\", line 165, in _loader_worker\n",
            "    _, data = next(data_iter)\n",
            "              ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/data_loader.py\", line 567, in __iter__\n",
            "    current_batch = next(dataloader_iter)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 708, in __next__\n",
            "    data = self._next_data()\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 764, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n",
            "    return self.collate_fn(data)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py\", line 683, in __call__\n",
            "    batch = pad_without_fast_tokenizer_warning(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py\", line 67, in pad_without_fast_tokenizer_warning\n",
            "    padded = tokenizer.pad(*pad_args, **pad_kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 3346, in pad\n",
            "    raise ValueError(\n",
            "ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['input_features']\n",
            "There seems not to be a single sample in your epoch_iterator, stopping training at step 0! This is expected if you're using an IterableDataset and set num_steps (39) higher than the number of available samples.\n"
          ]
        }
      ],
      "source": [
        "# Start training\n",
        "print(\"Starting model training...\")\n",
        "trainer = whisper_trainer.train(train_dataset, val_dataset, CONFIG)\n",
        "print(\"Training completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "114f0b46",
      "metadata": {
        "id": "114f0b46"
      },
      "source": [
        "## Module 4: Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6110f476",
      "metadata": {
        "id": "6110f476"
      },
      "outputs": [],
      "source": [
        "class ModelEvaluator:\n",
        "    \"\"\"Handles model evaluation and metrics computation.\"\"\"\n",
        "\n",
        "    def __init__(self, model_path: str):\n",
        "        self.model_path = model_path\n",
        "\n",
        "        # Load trained model\n",
        "        print(f\"Loading trained model from {model_path}...\")\n",
        "        self.model = WhisperForConditionalGeneration.from_pretrained(model_path)\n",
        "        self.processor = WhisperProcessor.from_pretrained(model_path)\n",
        "\n",
        "        # Load WER metric\n",
        "        self.wer_metric = evaluate.load(\"wer\")\n",
        "\n",
        "        print(\"Model and metrics loaded for evaluation.\")\n",
        "\n",
        "    def transcribe_audio(self, audio_features: torch.Tensor) -> str:\n",
        "        \"\"\"Transcribe audio features to text.\"\"\"\n",
        "        with torch.no_grad():\n",
        "            # Generate transcription\n",
        "            predicted_ids = self.model.generate(\n",
        "                audio_features,\n",
        "                max_length=225,\n",
        "                num_beams=1,\n",
        "                do_sample=False\n",
        "            )\n",
        "\n",
        "            # Decode to text\n",
        "            transcription = self.processor.tokenizer.batch_decode(\n",
        "                predicted_ids,\n",
        "                skip_special_tokens=True\n",
        "            )[0]\n",
        "\n",
        "            return transcription.strip()\n",
        "\n",
        "    def evaluate_dataset(self, dataset: Dataset, max_samples: Optional[int] = None) -> Dict:\n",
        "        \"\"\"Evaluate model on a dataset and compute metrics.\"\"\"\n",
        "        print(\"Running evaluation...\")\n",
        "\n",
        "        predictions = []\n",
        "        references = []\n",
        "\n",
        "        eval_samples = min(len(dataset), max_samples) if max_samples else len(dataset)\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        for i in range(eval_samples):\n",
        "            sample = dataset[i]\n",
        "\n",
        "            # Get input features\n",
        "            input_features = sample['input_features'].unsqueeze(0)\n",
        "\n",
        "            # Get reference text (decode labels)\n",
        "            reference = self.processor.tokenizer.decode(\n",
        "                sample['labels'],\n",
        "                skip_special_tokens=True\n",
        "            ).strip()\n",
        "\n",
        "            # Generate prediction\n",
        "            prediction = self.transcribe_audio(input_features)\n",
        "\n",
        "            predictions.append(prediction)\n",
        "            references.append(reference)\n",
        "\n",
        "            if (i + 1) % 50 == 0:\n",
        "                print(f\"Evaluated {i + 1}/{eval_samples} samples...\")\n",
        "\n",
        "        # Compute WER\n",
        "        wer_score = self.wer_metric.compute(predictions=predictions, references=references)\n",
        "\n",
        "        results = {\n",
        "            'wer': wer_score,\n",
        "            'num_samples': len(predictions),\n",
        "            'predictions': predictions[:5],  # First 5 for inspection\n",
        "            'references': references[:5]\n",
        "        }\n",
        "\n",
        "        return results\n",
        "\n",
        "    def print_evaluation_results(self, results: Dict):\n",
        "        \"\"\"Print evaluation results in a readable format.\"\"\"\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"EVALUATION RESULTS\")\n",
        "        print(\"=\"*50)\n",
        "        print(f\"Word Error Rate (WER): {results['wer']:.4f}\")\n",
        "        print(f\"Samples evaluated: {results['num_samples']}\")\n",
        "\n",
        "        print(\"\\nSample Predictions vs References:\")\n",
        "        print(\"-\"*50)\n",
        "\n",
        "        for i, (pred, ref) in enumerate(zip(results['predictions'], results['references'])):\n",
        "            print(f\"Sample {i+1}:\")\n",
        "            print(f\"  Reference: {ref}\")\n",
        "            print(f\"  Prediction: {pred}\")\n",
        "            print()\n",
        "\n",
        "# Initialize evaluator (will load the trained model)\n",
        "evaluator = ModelEvaluator(CONFIG['output_dir'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab01752d",
      "metadata": {
        "id": "ab01752d"
      },
      "outputs": [],
      "source": [
        "# Evaluate on validation set\n",
        "print(\"Evaluating model on validation set...\")\n",
        "eval_results = evaluator.evaluate_dataset(val_dataset, max_samples=100)  # Limit for speed\n",
        "\n",
        "# Print results\n",
        "evaluator.print_evaluation_results(eval_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "776c084d",
      "metadata": {
        "id": "776c084d"
      },
      "source": [
        "## Module 5: Inference and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32a0e1d5",
      "metadata": {
        "id": "32a0e1d5"
      },
      "outputs": [],
      "source": [
        "class InferenceEngine:\n",
        "    \"\"\"Handles inference on new audio samples.\"\"\"\n",
        "\n",
        "    def __init__(self, model_path: str):\n",
        "        self.model_path = model_path\n",
        "\n",
        "        # Load model and processor\n",
        "        print(f\"Loading model for inference from {model_path}...\")\n",
        "        self.model = WhisperForConditionalGeneration.from_pretrained(model_path)\n",
        "        self.processor = WhisperProcessor.from_pretrained(model_path)\n",
        "\n",
        "        # Set to eval mode\n",
        "        self.model.eval()\n",
        "\n",
        "        print(\"Inference engine ready.\")\n",
        "\n",
        "    def transcribe_from_features(self, input_features: torch.Tensor) -> str:\n",
        "        \"\"\"Transcribe audio from preprocessed features.\"\"\"\n",
        "        with torch.no_grad():\n",
        "            # Generate transcription\n",
        "            predicted_ids = self.model.generate(\n",
        "                input_features,\n",
        "                max_length=225,\n",
        "                num_beams=2,  # Slightly better quality\n",
        "                do_sample=False,\n",
        "                temperature=1.0\n",
        "            )\n",
        "\n",
        "            # Decode to text\n",
        "            transcription = self.processor.tokenizer.batch_decode(\n",
        "                predicted_ids,\n",
        "                skip_special_tokens=True\n",
        "            )[0]\n",
        "\n",
        "            return transcription.strip()\n",
        "\n",
        "    def transcribe_raw_audio(self, audio_array: np.ndarray, sampling_rate: int) -> str:\n",
        "        \"\"\"Transcribe from raw audio array.\"\"\"\n",
        "        # Preprocess audio\n",
        "        if sampling_rate != 16000:\n",
        "            # Resample to 16kHz\n",
        "            audio_tensor = torch.from_numpy(audio_array).float()\n",
        "            if len(audio_tensor.shape) == 1:\n",
        "                audio_tensor = audio_tensor.unsqueeze(0)\n",
        "\n",
        "            resampler = torchaudio.transforms.Resample(\n",
        "                orig_freq=sampling_rate,\n",
        "                new_freq=16000\n",
        "            )\n",
        "            audio_array = resampler(audio_tensor).squeeze().numpy()\n",
        "\n",
        "        # Extract features\n",
        "        features = self.processor.feature_extractor(\n",
        "            audio_array,\n",
        "            sampling_rate=16000,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Transcribe\n",
        "        return self.transcribe_from_features(features[\"input_features\"])\n",
        "\n",
        "    def demo_inference(self, dataset: Dataset, num_samples: int = 3):\n",
        "        \"\"\"Run demo inference on dataset samples.\"\"\"\n",
        "        print(f\"\\nRunning demo inference on {num_samples} samples...\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        for i in range(min(num_samples, len(dataset))):\n",
        "            sample = dataset[i]\n",
        "\n",
        "            # Get reference\n",
        "            reference = self.processor.tokenizer.decode(\n",
        "                sample['labels'],\n",
        "                skip_special_tokens=True\n",
        "            ).strip()\n",
        "\n",
        "            # Get prediction\n",
        "            input_features = sample['input_features'].unsqueeze(0)\n",
        "            prediction = self.transcribe_from_features(input_features)\n",
        "\n",
        "            # Display results\n",
        "            print(f\"\\nSample {i+1}:\")\n",
        "            print(f\"Reference:  {reference}\")\n",
        "            print(f\"Prediction: {prediction}\")\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "# Initialize inference engine\n",
        "inference_engine = InferenceEngine(CONFIG['output_dir'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a073980e",
      "metadata": {
        "id": "a073980e"
      },
      "outputs": [],
      "source": [
        "# Run demo inference\n",
        "inference_engine.demo_inference(val_dataset, num_samples=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcc6d968",
      "metadata": {
        "id": "bcc6d968"
      },
      "source": [
        "## Summary and Next Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71cd1e2f",
      "metadata": {
        "id": "71cd1e2f"
      },
      "outputs": [],
      "source": [
        "# Summary of the training run\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BASELINE ASR MODEL TRAINING COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Model: {CONFIG['model_name']}\")\n",
        "print(f\"Dataset: {CONFIG['dataset_name']}\")\n",
        "print(f\"Samples used: {CONFIG['num_samples']}\")\n",
        "print(f\"Training epochs: {CONFIG['num_epochs']}\")\n",
        "print(f\"Model saved to: {CONFIG['output_dir']}\")\n",
        "print(f\"Final WER: {eval_results['wer']:.4f}\")\n",
        "\n",
        "print(\"\\nNext Steps:\")\n",
        "print(\"1. Fine-tune hyperparameters for better WER\")\n",
        "print(\"2. Increase dataset size for more robust training\")\n",
        "print(\"3. Implement EHR structuring pipeline\")\n",
        "print(\"4. Add domain-specific medical vocabulary\")\n",
        "print(\"5. Evaluate on held-out test set\")\n",
        "\n",
        "print(\"\\nModel Files:\")\n",
        "import os\n",
        "if os.path.exists(CONFIG['output_dir']):\n",
        "    files = os.listdir(CONFIG['output_dir'])\n",
        "    for file in files:\n",
        "        print(f\"  - {file}\")\n",
        "else:\n",
        "    print(\"  Model directory not found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfaa16d3",
      "metadata": {
        "id": "dfaa16d3"
      },
      "source": [
        "## Optional: Test with Different Model Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2221322c",
      "metadata": {
        "id": "2221322c"
      },
      "outputs": [],
      "source": [
        "# Uncomment and run this cell to quickly test with Whisper Tiny for faster iteration\n",
        "\n",
        "# CONFIG_TINY = CONFIG.copy()\n",
        "# CONFIG_TINY['model_name'] = 'openai/whisper-tiny'\n",
        "# CONFIG_TINY['output_dir'] = './whisper-tiny-medical-asr'\n",
        "# CONFIG_TINY['num_epochs'] = 1  # Faster training\n",
        "# CONFIG_TINY['batch_size'] = 16  # Larger batch for smaller model\n",
        "\n",
        "# print(\"Testing with Whisper Tiny for faster iteration...\")\n",
        "# print(f\"Model: {CONFIG_TINY['model_name']}\")\n",
        "\n",
        "# # Quick training with tiny model\n",
        "# tiny_trainer = WhisperTrainer(\n",
        "#     model_name=CONFIG_TINY['model_name'],\n",
        "#     output_dir=CONFIG_TINY['output_dir']\n",
        "# )\n",
        "\n",
        "# # Use a smaller subset for quick testing\n",
        "# tiny_train = train_dataset.select(range(100))\n",
        "# tiny_val = val_dataset.select(range(20))\n",
        "\n",
        "# trainer_tiny = tiny_trainer.train(tiny_train, tiny_val, CONFIG_TINY)\n",
        "# print(\"Tiny model training complete!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7503814d808e4eb690bd18878830c037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b12f3652e0943f382d4a2647f52e24d",
              "IPY_MODEL_56184a1862b24d3e938478d43ffd40b2",
              "IPY_MODEL_c2ecdc4d35f148fb88b3b1811ff6e48b"
            ],
            "layout": "IPY_MODEL_27c5333a825e4bae9bfed11e68d63c91"
          }
        },
        "5b12f3652e0943f382d4a2647f52e24d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_827727c5571c4e549b19ba833383cc04",
            "placeholder": "",
            "style": "IPY_MODEL_7985d3a353ee439b86b487ed517a6045",
            "value": "Map:100%"
          }
        },
        "56184a1862b24d3e938478d43ffd40b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb7b53a0ad044e41b492ed7a1141b5cd",
            "max": 1600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1b5069892be4d19b4137d1e63f8f39b",
            "value": 1600
          }
        },
        "c2ecdc4d35f148fb88b3b1811ff6e48b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc59d945a8fb40fa90b76935e5e25abe",
            "placeholder": "",
            "style": "IPY_MODEL_e283cc8f91ac4715b9b4559bc7e7fc97",
            "value": "1600/1600[05:43&lt;00:00,5.08examples/s]"
          }
        },
        "27c5333a825e4bae9bfed11e68d63c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "827727c5571c4e549b19ba833383cc04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7985d3a353ee439b86b487ed517a6045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb7b53a0ad044e41b492ed7a1141b5cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1b5069892be4d19b4137d1e63f8f39b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc59d945a8fb40fa90b76935e5e25abe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e283cc8f91ac4715b9b4559bc7e7fc97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "436f694571ed47a9b5245958dbdd5c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bec3765290944905b31bd83ccc7df5dc",
              "IPY_MODEL_3f17f79f05574da18beb005d42a24949",
              "IPY_MODEL_160f17b30ba54275b7a63786006d9685"
            ],
            "layout": "IPY_MODEL_ecaf6210046e492e80b7cf0d1b096643"
          }
        },
        "bec3765290944905b31bd83ccc7df5dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33733c1510024b019402d79e63128885",
            "placeholder": "",
            "style": "IPY_MODEL_d5e1612fec2f423fa752900b5cb7923d",
            "value": "Map:100%"
          }
        },
        "3f17f79f05574da18beb005d42a24949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_711f01944c904cf4a774cd9c446a8ea2",
            "max": 400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4d7ae0ed68c4e7286f6b07e241fbfa5",
            "value": 400
          }
        },
        "160f17b30ba54275b7a63786006d9685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4c90494c98f4ac2bbf0ca2b787d624e",
            "placeholder": "",
            "style": "IPY_MODEL_3a3a3e7e601f44c49e120d1d77948891",
            "value": "400/400[01:23&lt;00:00,4.44examples/s]"
          }
        },
        "ecaf6210046e492e80b7cf0d1b096643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33733c1510024b019402d79e63128885": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5e1612fec2f423fa752900b5cb7923d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "711f01944c904cf4a774cd9c446a8ea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4d7ae0ed68c4e7286f6b07e241fbfa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4c90494c98f4ac2bbf0ca2b787d624e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a3a3e7e601f44c49e120d1d77948891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e943bb857ae7498c8598f2c53d5e309f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1cf9cdde54104a36812ef53fd76d30b2",
              "IPY_MODEL_3f67cc6429c242f1a3d4d3175ad12376",
              "IPY_MODEL_ff7986d246de4b1584a3b65d1831a71f"
            ],
            "layout": "IPY_MODEL_ba8d5a10ec414c6e880e587f2245b4bf"
          }
        },
        "1cf9cdde54104a36812ef53fd76d30b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30edfbd789fd47c480c7790bf3a5a1f9",
            "placeholder": "",
            "style": "IPY_MODEL_2f8e359964a94e0b98185c8accf828a4",
            "value": "config.json:"
          }
        },
        "3f67cc6429c242f1a3d4d3175ad12376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_148ed113e6bc42cb9f8db99a7ec24501",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f6805f03105477db2fe1936667dceed",
            "value": 1
          }
        },
        "ff7986d246de4b1584a3b65d1831a71f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a01c9677805f4bb0be8e40e8ca981db6",
            "placeholder": "",
            "style": "IPY_MODEL_bee8104aa7034fa694c4f7d7d22ed17d",
            "value": "1.98k/?[00:00&lt;00:00,243kB/s]"
          }
        },
        "ba8d5a10ec414c6e880e587f2245b4bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30edfbd789fd47c480c7790bf3a5a1f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f8e359964a94e0b98185c8accf828a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "148ed113e6bc42cb9f8db99a7ec24501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0f6805f03105477db2fe1936667dceed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a01c9677805f4bb0be8e40e8ca981db6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bee8104aa7034fa694c4f7d7d22ed17d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13ffc6bc1157413085ac279bc1a3b1c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb5d27bed62343ab9b7288dbdff3a4d0",
              "IPY_MODEL_26722dabb6b547c09aba4f36a9f02e92",
              "IPY_MODEL_d20490cc7b6b4b78997a4c2bafcbe56f"
            ],
            "layout": "IPY_MODEL_fb55a84387814c1fa4fc31d929cb8e37"
          }
        },
        "fb5d27bed62343ab9b7288dbdff3a4d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14390d6438a24acda32f30551e641082",
            "placeholder": "",
            "style": "IPY_MODEL_0e12614b29f4439581a5abd62e3df57e",
            "value": "model.safetensors:100%"
          }
        },
        "26722dabb6b547c09aba4f36a9f02e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5de06bb4bd5c42919fd22b2128fab43f",
            "max": 151061672,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d4e4bd257e94331ab4220e95f155a7a",
            "value": 151061672
          }
        },
        "d20490cc7b6b4b78997a4c2bafcbe56f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faddce1711bf42f197a69166a4bb8950",
            "placeholder": "",
            "style": "IPY_MODEL_9a93ba39234c46f2a2a0479d023af55c",
            "value": "151M/151M[00:01&lt;00:00,59.7MB/s]"
          }
        },
        "fb55a84387814c1fa4fc31d929cb8e37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14390d6438a24acda32f30551e641082": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e12614b29f4439581a5abd62e3df57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5de06bb4bd5c42919fd22b2128fab43f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d4e4bd257e94331ab4220e95f155a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "faddce1711bf42f197a69166a4bb8950": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a93ba39234c46f2a2a0479d023af55c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70118b8f3de84318939bd1175fb1c30d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2718c23fbf44259826b11ede3c01985",
              "IPY_MODEL_b260b1f8b7954b039dbb422f4a992452",
              "IPY_MODEL_e4adf9f679cb4eed89f3303fa31ae9dc"
            ],
            "layout": "IPY_MODEL_723635fe203d4fcabc1a6f26beb9ad17"
          }
        },
        "a2718c23fbf44259826b11ede3c01985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7ccace2bc0249ef87c513f97150aef9",
            "placeholder": "",
            "style": "IPY_MODEL_b0a86439822d43c6a22c8fb925929c92",
            "value": "generation_config.json:"
          }
        },
        "b260b1f8b7954b039dbb422f4a992452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86166738aa664bfc98e17ce7c5a0bed0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a38371bde29244a1a54980f7db83d4fc",
            "value": 1
          }
        },
        "e4adf9f679cb4eed89f3303fa31ae9dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee91dbe1383c4798a8098d7dc6713be9",
            "placeholder": "",
            "style": "IPY_MODEL_0c879a59d46742fdb8ecf01b982c74eb",
            "value": "3.75k/?[00:00&lt;00:00,454kB/s]"
          }
        },
        "723635fe203d4fcabc1a6f26beb9ad17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7ccace2bc0249ef87c513f97150aef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0a86439822d43c6a22c8fb925929c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86166738aa664bfc98e17ce7c5a0bed0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a38371bde29244a1a54980f7db83d4fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee91dbe1383c4798a8098d7dc6713be9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c879a59d46742fdb8ecf01b982c74eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}